'''腾讯新闻爬虫'''import  requestsimport jsonimport  csvclass TencentNews:    # 请求    def request(self,urls):        for url in urls :           string = requests.get(url).text           string_json = json.loads(string)           yield  string_json    # 解析    def parse(self,json_data_list):        for json_data in json_data_list:            datas = json_data["data"]            for data in datas :                data_dic = dict()                #文章id                data_dic['id']  = data['id']                # 类别                data_dic['category'] = data["category1_chn"]                # 封面图片                data_dic['img'] = data['img']                #图片组                data_dic['imgs']  = ','.join(list(data["imgs"].values()))                #文章标题                data_dic['title'] = data['title']                #文章内容                data_dic['info'] = data['intro']                # 浏览数                data_dic['view_count'] = data['view_count']                # 评论数                data_dic['comment_num'] = data['comment_num']                #关键字                data_dic['keywords']  = data["keywords"]                #新闻等级                data_dic['newlevel'] = data['news_level']                #标签                data_dic['tags'] = data['tags']                #作者                data_dic['source'] = data['source']                # 作者粉丝数                data_dic['source_fans'] = data['source_fans']                # 作者id                data_dic['source_id'] = data['source_id']                # 详细网页                data_dic['page_url'] = data['vurl']                # 更新时间                data_dic['update_time'] = data['update_time']                yield  data_dic    # 存储    def to_csv(self,datas):        with open('./news.csv',mode='a') as file:            writer = csv.writer(file)            writer.writerow(['文章id',"类别",'封面图片','图片组','文章标题','文章内容','浏览数',                             "评论数","关键字",'新闻等级',"标签","作者","作者粉丝数",'作者id',                             "详细网页","更新时间"])            data_list = [data.values() for data in datas]            writer.writerows(data_list)if __name__ == '__main__':    url = "https://pacaio.match.qq.com/irs/rcd?cid=146&token=49cbb2154853ef1a74ff4e53723372ce&ext={}&page={}"    new_type = ['games', "milite", "world", "auto", "fashion", "tech"]  # 游戏,军事,国际,汽车,时尚,科技    start_page,endpage = map(int,input("请输入起始页和终止页:").split())    urls = [url.format(type, str(page)) for type in new_type for page in range(start_page,endpage+1)]    news  = TencentNews()    # 请求    jsonList = news.request(urls)    # 解析    datas = news.parse(jsonList)    # 存储    news.to_csv(datas)